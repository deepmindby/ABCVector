#!/usr/bin/env python3
"""
ABC Vector è‡ªåŠ¨è°ƒå‚è„šæœ¬
======================

åŠŸèƒ½ï¼š
- å¯¹ ABC Vector çš„æ ¸å¿ƒå‚æ•°è¿›è¡Œç½‘æ ¼æœç´¢
- è‡ªåŠ¨è®°å½•æ—¥å¿—å’Œç”ŸæˆæŠ¥å‘Š
- é”™è¯¯æ—¶å‘é€é‚®ä»¶é€šçŸ¥
- æ˜¾ç¤ºæ¸…æ™°çš„è¿›åº¦æ¡
- è‡ªåŠ¨ä¿å­˜æœ€ä½³å‚æ•°çš„æ¨¡å‹å‘é‡åˆ° outputs/{dataset}_best/

ä½¿ç”¨æ–¹æ³•ï¼š
    python abc_hyperparameter_search.py

ä½œè€…ï¼šCoT Vectors Research
"""

import os
import sys
import json
import time
import shutil
import logging
import traceback
import smtplib
import subprocess
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from itertools import product
from tqdm import tqdm
import gc

# ============================================================================
# é…ç½®åŒº - åœ¨æ­¤ä¿®æ”¹æ¨¡å‹ã€æ•°æ®é›†å’Œè·¯å¾„
# ============================================================================

# æ¨¡å‹é…ç½®
MODEL_PATH = "/home/haichao/TA/ABCVector/models/Qwen2.5-Math-7B"
MODEL_NAME = "qwen"  # "qwen" æˆ– "llama"

# æ•°æ®é›†é…ç½®
DATASET = "math_easy"  # "gsm8k", "math_easy", "math_hard", "mmlu_pro"
DATA_PATH = "/home/haichao/TA/ABCVector/data"

# è¾“å‡ºè·¯å¾„
RESULTS_DIR = "./results"

# æœ€ä½³æ¨¡å‹è¾“å‡ºè·¯å¾„ (outputs/{dataset}_best/)
BEST_OUTPUT_BASE = "./outputs"

# é‚®ä»¶é…ç½® - è¯¦ç»†é…ç½®è¯·ä¿®æ”¹ email_helper.py
# æ”¶ä»¶äººé‚®ç®±
EMAIL_RECIPIENT = "byboyuanzhang@gmail.com"

# ============================================================================
# è°ƒå‚é…ç½®
# ============================================================================

# å‚æ•°æœç´¢ç©ºé—´
PARAM_GRID = {
    "kl_beta": [0.5, 1.0, 2.0],
    "kl_warmup_steps": [0],
    "abc_learning_rate": [5e-5, 1e-4, 5e-4],
}

# å›ºå®šå‚æ•°
FIXED_PARAMS = {
    "num_epochs": 10,
    "batch_size": 2,
    "gradient_accumulation_steps": 2,
    "abc_hidden_dim": 512,
    "sigma_min": 1e-4,
    "max_length": 1024,
    "warmup_ratio": 0.1,
    "weight_decay": 1e-3,
    "num_support_samples": 3000,
    "num_test_samples": 100,
    "max_new_tokens": 512,
    "num_beams": 3,
}

# æµ‹è¯•å±‚èŒƒå›´
LAYERS = list(range(0, 27, 2))  # 0, 2, 4, ..., 26

# ============================================================================
# æ•°æ®ç»“æ„
# ============================================================================

@dataclass
class LayerResult:
    """å•å±‚ç»“æœ"""
    layer: int
    accuracy: float
    correct: int
    total: int
    gate: float = 0.0
    error: Optional[str] = None


@dataclass
class ExperimentResult:
    """å•æ¬¡å®éªŒç»“æœ"""
    params: Dict[str, Any]
    layer_results: List[LayerResult] = field(default_factory=list)
    avg_accuracy: float = 0.0
    max_accuracy: float = 0.0
    best_layer: int = -1
    total_time: float = 0.0
    status: str = "pending"  # pending, running, completed, failed
    error_message: Optional[str] = None
    
    def compute_stats(self):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        valid_results = [r for r in self.layer_results if r.error is None]
        if valid_results:
            accuracies = [r.accuracy for r in valid_results]
            self.avg_accuracy = sum(accuracies) / len(accuracies)
            self.max_accuracy = max(accuracies)
            self.best_layer = valid_results[accuracies.index(self.max_accuracy)].layer


@dataclass
class SearchResults:
    """æœç´¢ç»“æœæ±‡æ€»"""
    model_path: str
    model_name: str
    dataset: str
    start_time: str
    end_time: str = ""
    total_experiments: int = 0
    completed_experiments: int = 0
    failed_experiments: int = 0
    experiments: List[ExperimentResult] = field(default_factory=list)
    best_experiment_idx: int = -1
    baseline_accuracy: float = 0.0
    
    def find_best(self):
        """æ‰¾åˆ°æœ€ä½³å®éªŒ"""
        valid_exps = [i for i, e in enumerate(self.experiments) 
                      if e.status == "completed"]
        if valid_exps:
            # æŒ‰ avg_accuracy æ’åº
            best_idx = max(valid_exps, key=lambda i: self.experiments[i].avg_accuracy)
            self.best_experiment_idx = best_idx


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def setup_logging(results_dir: str, dataset: str) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—"""
    os.makedirs(results_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(results_dir, f"abc_tuning_{dataset}_{timestamp}.log")
    
    # åˆ›å»º logger
    logger = logging.getLogger("abc_tuning")
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤å·²æœ‰çš„ handlers
    logger.handlers.clear()
    
    # æ–‡ä»¶ handler - è¯¦ç»†æ—¥å¿—
    file_handler = logging.FileHandler(log_file, encoding="utf-8")
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(
        "%(asctime)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)
    
    # æ§åˆ¶å° handler - ç®€æ´è¾“å‡º
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter("%(message)s")
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)
    
    return logger


def send_email(subject: str, body: str, is_error: bool = False):
    """å‘é€é‚®ä»¶é€šçŸ¥ï¼ˆä½¿ç”¨ email_helper æ¨¡å—ï¼‰"""
    try:
        # å°è¯•å¯¼å…¥ email_helper æ¨¡å—
        from email_helper import send_email as _send_email_impl
        _send_email_impl(subject, body, is_error, EMAIL_RECIPIENT)
    except ImportError:
        # æ¨¡å—ä¸å­˜åœ¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        print(f"ğŸ“§ [é‚®ä»¶é€šçŸ¥] {subject}")
        if is_error:
            print(f"   (é‚®ä»¶æ¨¡å—æœªé…ç½®ï¼Œè¯·å‚è€ƒ email_helper.py)")
        # å°è¯•ç³»ç»Ÿ mail å‘½ä»¤
        try:
            subprocess.run(
                ["mail", "-s", f"[ABCè°ƒå‚] {subject}", EMAIL_RECIPIENT],
                input=body.encode(),
                timeout=10,
                capture_output=True
            )
        except:
            pass
    except Exception as e:
        print(f"âš ï¸ é‚®ä»¶å‘é€å¤±è´¥: {e}")


def format_params(params: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–å‚æ•°æ˜¾ç¤º"""
    return ", ".join([f"{k}={v}" for k, v in params.items()])


def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        return f"{seconds/60:.1f}åˆ†é’Ÿ"
    else:
        return f"{seconds/3600:.1f}å°æ—¶"


# ============================================================================
# æ ¸å¿ƒè°ƒå‚é€»è¾‘
# ============================================================================

class ABCHyperparameterSearch:
    """ABC Vector è¶…å‚æ•°æœç´¢"""
    
    def __init__(
        self,
        model_path: str,
        model_name: str,
        dataset: str,
        data_path: str,
        results_dir: str,
        param_grid: Dict[str, List],
        fixed_params: Dict[str, Any],
        layers: List[int],
        best_output_base: str = "./outputs",
    ):
        self.model_path = model_path
        self.model_name = model_name
        self.dataset = dataset
        self.data_path = data_path
        self.results_dir = results_dir
        self.param_grid = param_grid
        self.fixed_params = fixed_params
        self.layers = layers
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = os.path.join(results_dir, dataset)
        os.makedirs(self.output_dir, exist_ok=True)
        
        # æœ€ä½³æ¨¡å‹è¾“å‡ºç›®å½•: outputs/{dataset}_best/
        self.best_output_dir = os.path.join(best_output_base, f"{dataset}_best")
        
        # å½“å‰å…¨å±€æœ€ä½³æ€§èƒ½ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°ï¼‰
        self.best_avg_accuracy = -1.0
        self.best_max_accuracy = -1.0
        self.best_params = None
        self.best_experiment_index = -1
        
        # å¦‚æœå·²æœ‰æœ€ä½³ç›®å½•ï¼Œå°è¯•åŠ è½½ä¹‹å‰çš„æœ€ä½³æ€§èƒ½
        self._load_existing_best()
        
        # è®¾ç½®æ—¥å¿—
        self.logger = setup_logging(self.output_dir, dataset)
        
        # åˆå§‹åŒ–ç»“æœ
        self.search_results = SearchResults(
            model_path=model_path,
            model_name=model_name,
            dataset=dataset,
            start_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        )
        
        # ç”Ÿæˆå‚æ•°ç»„åˆ
        self.param_combinations = self._generate_param_combinations()
        self.search_results.total_experiments = len(self.param_combinations)
        
        # æ¨¡å‹å’Œæ•°æ®ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        self.model_wrapper = None
        self.tokenizer = None
        self.support_samples = None
        self.test_samples = None
    
    def _load_existing_best(self):
        """åŠ è½½å·²æœ‰çš„æœ€ä½³æ€§èƒ½è®°å½•ï¼ˆç”¨äºæ¢å¤æœç´¢ï¼‰"""
        meta_path = os.path.join(self.best_output_dir, "best_meta.json")
        if os.path.exists(meta_path):
            try:
                with open(meta_path, "r", encoding="utf-8") as f:
                    meta = json.load(f)
                self.best_avg_accuracy = meta.get("avg_accuracy", -1.0)
                self.best_max_accuracy = meta.get("max_accuracy", -1.0)
                self.best_params = meta.get("params", None)
                print(f"ğŸ“‚ å·²åŠ è½½å†å²æœ€ä½³è®°å½•: å¹³å‡å‡†ç¡®ç‡={self.best_avg_accuracy:.2f}%, "
                      f"æœ€é«˜å‡†ç¡®ç‡={self.best_max_accuracy:.2f}%")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åŠ è½½å†å²æœ€ä½³è®°å½•: {e}")
        
    def _generate_param_combinations(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ"""
        keys = list(self.param_grid.keys())
        values = list(self.param_grid.values())
        
        combinations = []
        for combo in product(*values):
            params = dict(zip(keys, combo))
            combinations.append(params)
        
        return combinations
    
    def _load_model_and_data(self):
        """åŠ è½½æ¨¡å‹å’Œæ•°æ®"""
        self.logger.info("=" * 70)
        self.logger.info("åŠ è½½æ¨¡å‹å’Œæ•°æ®...")
        self.logger.info("=" * 70)
        
        # å¯¼å…¥å¿…è¦æ¨¡å—
        import torch
        from src.models import CoTModelWrapper, load_tokenizer
        from src.data_utils import load_dataset
        from src.utils import set_seed
        
        set_seed(42)
        
        # åŠ è½½æ¨¡å‹
        self.logger.info(f"æ¨¡å‹è·¯å¾„: {self.model_path}")
        self.model_wrapper = CoTModelWrapper(self.model_path, self.model_name)
        self.tokenizer = load_tokenizer(self.model_path)
        self.logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ: {self.model_wrapper.num_layers} å±‚, "
                        f"hidden_size={self.model_wrapper.hidden_size}")
        
        # åŠ è½½æ•°æ®
        self.logger.info(f"æ•°æ®é›†: {self.dataset}")
        self.logger.info(f"æ•°æ®è·¯å¾„: {self.data_path}")
        
        self.support_samples = load_dataset(
            self.data_path, self.dataset, "train", 
            self.fixed_params["num_support_samples"]
        )
        self.test_samples = load_dataset(
            self.data_path, self.dataset, "test",
            self.fixed_params["num_test_samples"]
        )
        
        self.logger.info(f"æ”¯æŒé›†: {len(self.support_samples)} æ ·æœ¬")
        self.logger.info(f"æµ‹è¯•é›†: {len(self.test_samples)} æ ·æœ¬")
    
    def _run_baseline(self) -> float:
        """è¿è¡ŒåŸºçº¿è¯„ä¼°"""
        self.logger.info("")
        self.logger.info("=" * 70)
        self.logger.info("åŸºçº¿è¯„ä¼° (æ—  CoT Vector æ³¨å…¥)")
        self.logger.info("=" * 70)
        
        from src.eval import run_baseline_evaluation
        
        baseline_results = run_baseline_evaluation(
            model_wrapper=self.model_wrapper,
            tokenizer=self.tokenizer,
            test_samples=self.test_samples,
            dataset_type=self.dataset,
            max_new_tokens=self.fixed_params["max_new_tokens"],
            num_beams=self.fixed_params["num_beams"],
            use_early_stopping=False,
        )
        
        accuracy = baseline_results["accuracy"]
        self.search_results.baseline_accuracy = accuracy
        self.logger.info(f"åŸºçº¿å‡†ç¡®ç‡: {accuracy:.2f}% "
                        f"({baseline_results['correct']}/{baseline_results['total']})")
        
        return accuracy
    
    def _save_best_checkpoints(
        self,
        layer_checkpoints: Dict[int, Dict[str, Any]],
        experiment_result: ExperimentResult,
        exp_idx: int,
    ):
        """
        ä¿å­˜æœ€ä½³å®éªŒçš„æ‰€æœ‰å±‚ checkpoint åˆ° outputs/{dataset}_best/
        
        ç›®å½•ç»“æ„:
            outputs/{dataset}_best/
            â”œâ”€â”€ best_meta.json          # å…ƒä¿¡æ¯ï¼ˆå‚æ•°ã€æ€§èƒ½ã€æ—¶é—´æˆ³ï¼‰
            â”œâ”€â”€ abc_L0.pt               # å„å±‚ checkpoint
            â”œâ”€â”€ abc_L2.pt
            â”œâ”€â”€ abc_L4.pt
            â””â”€â”€ ...
        
        Args:
            layer_checkpoints: {layer_idx: state_dict} å„å±‚çš„æ¨¡å‹çŠ¶æ€
            experiment_result: è¯¥å®éªŒçš„ç»“æœ
            exp_idx: å®éªŒç¼–å·
        """
        import torch
        
        self.logger.info("")
        self.logger.info("ğŸ† å‘ç°æ–°çš„æœ€ä½³æ€§èƒ½ï¼ä¿å­˜æœ€ä½³æ¨¡å‹...")
        self.logger.info(f"   æ—§æœ€ä½³: å¹³å‡={self.best_avg_accuracy:.2f}%")
        self.logger.info(f"   æ–°æœ€ä½³: å¹³å‡={experiment_result.avg_accuracy:.2f}%, "
                        f"æœ€é«˜=L{experiment_result.best_layer} {experiment_result.max_accuracy:.2f}%")
        
        # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œæ¸…ç©ºæ—§æ–‡ä»¶
        if os.path.exists(self.best_output_dir):
            shutil.rmtree(self.best_output_dir)
        os.makedirs(self.best_output_dir, exist_ok=True)
        
        # ä¿å­˜æ¯ä¸€å±‚çš„ checkpoint
        saved_layers = []
        for layer_idx, state_dict in sorted(layer_checkpoints.items()):
            checkpoint_path = os.path.join(self.best_output_dir, f"abc_L{layer_idx}.pt")
            
            save_data = {
                **state_dict,
                "args": {
                    **experiment_result.params,
                    **self.fixed_params,
                    "model_path": self.model_path,
                    "model_name": self.model_name,
                    "dataset": self.dataset,
                    "layer_idx": layer_idx,
                },
            }
            torch.save(save_data, checkpoint_path)
            saved_layers.append(layer_idx)
        
        # ä¿å­˜å…ƒä¿¡æ¯
        meta = {
            "params": experiment_result.params,
            "fixed_params": self.fixed_params,
            "avg_accuracy": experiment_result.avg_accuracy,
            "max_accuracy": experiment_result.max_accuracy,
            "best_layer": experiment_result.best_layer,
            "baseline_accuracy": self.search_results.baseline_accuracy,
            "improvement_over_baseline": experiment_result.avg_accuracy - self.search_results.baseline_accuracy,
            "experiment_index": exp_idx,
            "total_time": experiment_result.total_time,
            "saved_layers": saved_layers,
            "model_path": self.model_path,
            "model_name": self.model_name,
            "dataset": self.dataset,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "layer_details": [
                {
                    "layer": lr.layer,
                    "accuracy": lr.accuracy,
                    "correct": lr.correct,
                    "total": lr.total,
                    "gate": lr.gate,
                }
                for lr in experiment_result.layer_results
                if lr.error is None
            ],
        }
        
        meta_path = os.path.join(self.best_output_dir, "best_meta.json")
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        
        # æ›´æ–°å…¨å±€æœ€ä½³è®°å½•
        self.best_avg_accuracy = experiment_result.avg_accuracy
        self.best_max_accuracy = experiment_result.max_accuracy
        self.best_params = experiment_result.params.copy()
        self.best_experiment_index = exp_idx
        
        self.logger.info(f"   å·²ä¿å­˜ {len(saved_layers)} å±‚ checkpoint åˆ°: {self.best_output_dir}")
        self.logger.info(f"   å…ƒä¿¡æ¯: {meta_path}")
        
        print(f"  ğŸ† æœ€ä½³æ¨¡å‹å·²æ›´æ–° â†’ {self.best_output_dir} "
              f"({len(saved_layers)} å±‚)")
    
    def run_search(self):
        """è¿è¡Œè¶…å‚æ•°æœç´¢"""
        import torch
        
        self.logger.info("")
        self.logger.info("=" * 70)
        self.logger.info("ABC Vector è¶…å‚æ•°æœç´¢")
        self.logger.info("=" * 70)
        self.logger.info(f"æ¨¡å‹: {self.model_path.split('/')[-1]}")
        self.logger.info(f"æ•°æ®é›†: {self.dataset}")
        self.logger.info(f"æµ‹è¯•å±‚: {self.layers}")
        self.logger.info(f"å‚æ•°ç»„åˆæ€»æ•°: {len(self.param_combinations)}")
        self.logger.info(f"æœ€ä½³æ¨¡å‹ä¿å­˜ç›®å½•: {self.best_output_dir}")
        self.logger.info("")
        
        # æ‰“å°å‚æ•°æœç´¢ç©ºé—´
        self.logger.info("å‚æ•°æœç´¢ç©ºé—´:")
        for param, values in self.param_grid.items():
            self.logger.info(f"  {param}: {values}")
        self.logger.info("")
        
        self.logger.info("å›ºå®šå‚æ•°:")
        for param, value in self.fixed_params.items():
            self.logger.info(f"  {param}: {value}")
        self.logger.info("=" * 70)
        
        if self.best_avg_accuracy > 0:
            self.logger.info(f"å†å²æœ€ä½³: å¹³å‡={self.best_avg_accuracy:.2f}%, "
                            f"å‚æ•°={format_params(self.best_params) if self.best_params else 'N/A'}")
        
        # åŠ è½½æ¨¡å‹å’Œæ•°æ®
        self._load_model_and_data()
        
        # è¿è¡ŒåŸºçº¿
        baseline_acc = self._run_baseline()
        
        # å¼€å§‹æœç´¢
        self.logger.info("")
        self.logger.info("=" * 70)
        self.logger.info("å¼€å§‹è¶…å‚æ•°æœç´¢...")
        self.logger.info("=" * 70)
        
        # ä¸»è¿›åº¦æ¡
        total_combinations = len(self.param_combinations)
        
        for exp_idx, params in enumerate(self.param_combinations):
            exp_num = exp_idx + 1
            
            self.logger.info("")
            self.logger.info(f"{'='*70}")
            self.logger.info(f"å®éªŒ {exp_num}/{total_combinations}")
            self.logger.info(f"å‚æ•°: {format_params(params)}")
            self.logger.info(f"{'='*70}")
            
            try:
                # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå±‚çº§è¿›åº¦
                print(f"\nğŸ“Š å®éªŒ {exp_num}/{total_combinations}: {format_params(params)}")
                
                result = ExperimentResult(params=params.copy())
                result.status = "running"
                start_time = time.time()
                
                # æœ¬æ¬¡å®éªŒå„å±‚çš„ checkpointï¼ˆç”¨äºä¿å­˜æœ€ä½³æ¨¡å‹ï¼‰
                layer_checkpoints = {}
                
                # å±‚çº§è¿›åº¦æ¡
                layer_pbar = tqdm(
                    self.layers, 
                    desc="  å±‚æµ‹è¯•",
                    ncols=100,
                    leave=True
                )
                
                for layer_idx in layer_pbar:
                    layer_pbar.set_description(f"  L{layer_idx:02d}")
                    
                    try:
                        # åˆ›å»ºå¹¶è®­ç»ƒ ABC
                        abc_method = self._create_abc_method(layer_idx, params)
                        
                        # è®­ç»ƒï¼ˆç®€åŒ–è¾“å‡ºï¼‰
                        self._train_silent(abc_method)
                        
                        # è¯„ä¼°
                        eval_results = self._eval_silent(abc_method)
                        
                        layer_result = LayerResult(
                            layer=layer_idx,
                            accuracy=eval_results["accuracy"],
                            correct=eval_results["correct"],
                            total=eval_results["total"],
                            gate=abc_method.gate.item(),
                        )
                        
                        # ä¿å­˜è¯¥å±‚çš„ state_dictï¼ˆå†…å­˜ä¸­æš‚å­˜ï¼‰
                        layer_checkpoints[layer_idx] = abc_method.get_state_dict()
                        
                        # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                        layer_pbar.set_postfix({
                            "acc": f"{eval_results['accuracy']:.1f}%",
                            "gate": f"{abc_method.gate.item():.3f}"
                        })
                        
                    except torch.cuda.OutOfMemoryError as e:
                        torch.cuda.empty_cache()
                        gc.collect()
                        error_msg = f"CUDA OOM at layer {layer_idx}"
                        self.logger.error(error_msg)
                        
                        # å‘é€é”™è¯¯é‚®ä»¶
                        send_email(
                            subject=f"âŒ é”™è¯¯: {self.dataset} å®éªŒ {exp_num}",
                            body=f"å®éªŒå‚æ•°: {format_params(params)}\n\n"
                                 f"é”™è¯¯ä¿¡æ¯: {error_msg}\n{str(e)}\n\n"
                                 f"å·²åœæ­¢å½“å‰å®éªŒã€‚",
                            is_error=True
                        )
                        
                        # è®°å½•é”™è¯¯å¹¶è·³è¿‡è¯¥å®éªŒ
                        result.status = "failed"
                        result.error_message = error_msg
                        result.total_time = time.time() - start_time
                        self.search_results.experiments.append(result)
                        self.search_results.failed_experiments += 1
                        break
                        
                    except Exception as e:
                        layer_result = LayerResult(
                            layer=layer_idx,
                            accuracy=0.0,
                            correct=0,
                            total=len(self.test_samples),
                            error=str(e)[:200],
                        )
                        layer_pbar.set_postfix({"error": "âš ï¸"})
                    
                    result.layer_results.append(layer_result)
                    
                    # æ¸…ç†æ˜¾å­˜
                    torch.cuda.empty_cache()
                    gc.collect()
                
                layer_pbar.close()
                
                # å¦‚æœå®éªŒæˆåŠŸå®Œæˆ
                if result.status != "failed":
                    result.compute_stats()
                    result.status = "completed"
                    result.total_time = time.time() - start_time
                    self.search_results.experiments.append(result)
                    self.search_results.completed_experiments += 1
                    
                    # æ‰“å°ç»“æœæ‘˜è¦
                    diff = result.avg_accuracy - baseline_acc
                    print(f"  âœ“ å®Œæˆ: å¹³å‡={result.avg_accuracy:.2f}% (Î”{diff:+.2f}%), "
                          f"æœ€ä½³=L{result.best_layer} {result.max_accuracy:.2f}%, "
                          f"è€—æ—¶={format_time(result.total_time)}")
                    
                    self.logger.info(f"å®éªŒå®Œæˆ: å¹³å‡å‡†ç¡®ç‡={result.avg_accuracy:.2f}%, "
                                    f"æœ€ä½³å±‚={result.best_layer}, "
                                    f"æœ€ä½³å‡†ç¡®ç‡={result.max_accuracy:.2f}%, "
                                    f"è€—æ—¶={format_time(result.total_time)}")
                    
                    # ========== æ£€æŸ¥æ˜¯å¦ä¸ºå…¨å±€æœ€ä½³ï¼Œä¿å­˜æœ€ä½³æ¨¡å‹ ==========
                    if result.avg_accuracy > self.best_avg_accuracy and layer_checkpoints:
                        self._save_best_checkpoints(
                            layer_checkpoints, result, exp_idx
                        )
                    else:
                        self.logger.info(f"  å½“å‰: {result.avg_accuracy:.2f}% "
                                        f"<= æœ€ä½³: {self.best_avg_accuracy:.2f}%, ä¸æ›´æ–°")
                
                # é‡Šæ”¾æœ¬æ¬¡å®éªŒçš„ checkpoint å†…å­˜
                del layer_checkpoints
                gc.collect()
                
            except Exception as e:
                error_msg = f"å®éªŒ {exp_num} å¤±è´¥: {str(e)}"
                self.logger.error(error_msg)
                self.logger.error(traceback.format_exc())
                
                # å‘é€é”™è¯¯é‚®ä»¶
                send_email(
                    subject=f"âŒ ä¸¥é‡é”™è¯¯: {self.dataset} å®éªŒ {exp_num}",
                    body=f"å®éªŒå‚æ•°: {format_params(params)}\n\n"
                         f"é”™è¯¯ä¿¡æ¯: {error_msg}\n\n"
                         f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}\n\n"
                         f"æœç´¢å·²ç»ˆæ­¢ã€‚",
                    is_error=True
                )
                
                # ä¿å­˜å½“å‰è¿›åº¦
                self._save_intermediate_results()
                
                # æŠ›å‡ºå¼‚å¸¸ç»ˆæ­¢
                raise RuntimeError(error_msg)
        
        # æœç´¢å®Œæˆ
        self.search_results.end_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.search_results.find_best()
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()
        
        # å‘é€å®Œæˆé‚®ä»¶
        best_info = ""
        if self.best_avg_accuracy > 0 and self.best_params:
            best_info = (
                f"\nå…¨å±€æœ€ä½³é…ç½®:\n{format_params(self.best_params)}\n\n"
                f"å…¨å±€æœ€ä½³ç»“æœ:\n"
                f"  å¹³å‡å‡†ç¡®ç‡: {self.best_avg_accuracy:.2f}%\n"
                f"  æœ€é«˜å‡†ç¡®ç‡: {self.best_max_accuracy:.2f}%\n"
                f"  æå‡: {self.best_avg_accuracy - baseline_acc:+.2f}%\n\n"
                f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {self.best_output_dir}\n"
            )
        
        if self.search_results.best_experiment_idx >= 0:
            best_exp = self.search_results.experiments[self.search_results.best_experiment_idx]
            send_email(
                subject=f"âœ… å®Œæˆ: {self.dataset} è¶…å‚æ•°æœç´¢",
                body=f"è¶…å‚æ•°æœç´¢å·²å®Œæˆï¼\n\n"
                     f"æ•°æ®é›†: {self.dataset}\n"
                     f"å®Œæˆå®éªŒ: {self.search_results.completed_experiments}/{self.search_results.total_experiments}\n"
                     f"åŸºçº¿å‡†ç¡®ç‡: {baseline_acc:.2f}%\n"
                     f"{best_info}\n"
                     f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {self.output_dir}"
            )
    
    def _create_abc_method(self, layer_idx: int, params: Dict[str, Any]):
        """åˆ›å»º ABC æ–¹æ³•å®ä¾‹"""
        from src.methods.abc_vector import ABCCoTVector
        
        return ABCCoTVector(
            model_wrapper=self.model_wrapper,
            tokenizer=self.tokenizer,
            layer_idx=layer_idx,
            dataset_type=self.dataset,
            abc_hidden_dim=self.fixed_params["abc_hidden_dim"],
            kl_beta=params["kl_beta"],
            kl_warmup_steps=params["kl_warmup_steps"],
            sigma_min=self.fixed_params["sigma_min"],
            learning_rate=params["abc_learning_rate"],
            weight_decay=self.fixed_params["weight_decay"],
            warmup_ratio=self.fixed_params["warmup_ratio"],
            num_epochs=self.fixed_params["num_epochs"],
            batch_size=self.fixed_params["batch_size"],
            gradient_accumulation_steps=self.fixed_params["gradient_accumulation_steps"],
            max_length=self.fixed_params["max_length"],
        )
    
    def _train_silent(self, abc_method):
        """é™é»˜è®­ç»ƒï¼ˆéšè—è¯¦ç»†è¾“å‡ºï¼‰"""
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        sys.stdout = open(os.devnull, 'w')
        sys.stderr = open(os.devnull, 'w')
        
        try:
            abc_method.train(self.support_samples, wandb_run=None)
        finally:
            sys.stdout.close()
            sys.stderr.close()
            sys.stdout = old_stdout
            sys.stderr = old_stderr
    
    def _eval_silent(self, abc_method) -> Dict[str, Any]:
        """é™é»˜è¯„ä¼°ï¼ˆéšè—è¯¦ç»†è¾“å‡ºï¼‰"""
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        sys.stdout = open(os.devnull, 'w')
        sys.stderr = open(os.devnull, 'w')
        
        try:
            results = abc_method.eval(
                test_samples=self.test_samples,
                max_new_tokens=self.fixed_params["max_new_tokens"],
                num_beams=self.fixed_params["num_beams"],
                use_early_stopping=False,
            )
        finally:
            sys.stdout.close()
            sys.stderr.close()
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        return results
    
    def _save_intermediate_results(self):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜ JSON ç»“æœ
        results_file = os.path.join(
            self.output_dir, 
            f"abc_tuning_intermediate_{timestamp}.json"
        )
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        results_dict = {
            "model_path": self.search_results.model_path,
            "model_name": self.search_results.model_name,
            "dataset": self.search_results.dataset,
            "start_time": self.search_results.start_time,
            "baseline_accuracy": self.search_results.baseline_accuracy,
            "total_experiments": self.search_results.total_experiments,
            "completed_experiments": self.search_results.completed_experiments,
            "failed_experiments": self.search_results.failed_experiments,
            "best_avg_accuracy": self.best_avg_accuracy,
            "best_params": self.best_params,
            "best_output_dir": self.best_output_dir,
            "experiments": []
        }
        
        for exp in self.search_results.experiments:
            exp_dict = {
                "params": exp.params,
                "avg_accuracy": exp.avg_accuracy,
                "max_accuracy": exp.max_accuracy,
                "best_layer": exp.best_layer,
                "total_time": exp.total_time,
                "status": exp.status,
                "error_message": exp.error_message,
                "layer_results": [
                    {
                        "layer": lr.layer,
                        "accuracy": lr.accuracy,
                        "correct": lr.correct,
                        "total": lr.total,
                        "gate": lr.gate,
                        "error": lr.error,
                    }
                    for lr in exp.layer_results
                ]
            }
            results_dict["experiments"].append(exp_dict)
        
        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"ä¸­é—´ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    def _generate_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜ JSON ç»“æœ
        json_file = os.path.join(
            self.output_dir, 
            f"abc_tuning_results_{timestamp}.json"
        )
        self._save_intermediate_results()  # å¤ç”¨ä¿å­˜é€»è¾‘
        
        # ç”Ÿæˆä¸­æ–‡æŠ¥å‘Š
        report_file = os.path.join(
            self.output_dir,
            f"abc_tuning_report_{timestamp}.md"
        )
        
        report_lines = [
            "# ABC Vector è¶…å‚æ•°æœç´¢æŠ¥å‘Š",
            "",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "## 1. å®éªŒé…ç½®",
            "",
            f"- **æ¨¡å‹**: {self.model_path.split('/')[-1]}",
            f"- **æ•°æ®é›†**: {self.dataset}",
            f"- **æµ‹è¯•å±‚**: {self.layers}",
            f"- **å¼€å§‹æ—¶é—´**: {self.search_results.start_time}",
            f"- **ç»“æŸæ—¶é—´**: {self.search_results.end_time}",
            f"- **æœ€ä½³æ¨¡å‹ç›®å½•**: `{self.best_output_dir}`",
            "",
            "### å‚æ•°æœç´¢ç©ºé—´",
            "",
            "| å‚æ•° | å–å€¼èŒƒå›´ |",
            "|------|----------|",
        ]
        
        for param, values in self.param_grid.items():
            report_lines.append(f"| {param} | {values} |")
        
        report_lines.extend([
            "",
            "### å›ºå®šå‚æ•°",
            "",
            "| å‚æ•° | å€¼ |",
            "|------|-----|",
        ])
        
        for param, value in self.fixed_params.items():
            report_lines.append(f"| {param} | {value} |")
        
        report_lines.extend([
            "",
            "## 2. å®éªŒç»“æœæ€»è§ˆ",
            "",
            f"- **æ€»å®éªŒæ•°**: {self.search_results.total_experiments}",
            f"- **å®Œæˆå®éªŒ**: {self.search_results.completed_experiments}",
            f"- **å¤±è´¥å®éªŒ**: {self.search_results.failed_experiments}",
            f"- **åŸºçº¿å‡†ç¡®ç‡**: {self.search_results.baseline_accuracy:.2f}%",
            "",
        ])
        
        # æœ€ä½³ç»“æœ
        if self.best_avg_accuracy > 0 and self.best_params:
            improvement = self.best_avg_accuracy - self.search_results.baseline_accuracy
            
            report_lines.extend([
                "## 3. ğŸ† æœ€ä½³é…ç½®ï¼ˆå·²ä¿å­˜åˆ°ç£ç›˜ï¼‰",
                "",
                f"**ä¿å­˜ä½ç½®**: `{self.best_output_dir}`",
                "",
                "### æœ€ä½³å‚æ•°",
                "",
                "| å‚æ•° | å€¼ |",
                "|------|-----|",
            ])
            
            for param, value in self.best_params.items():
                report_lines.append(f"| {param} | {value} |")
            
            report_lines.extend([
                "",
                "### æœ€ä½³ç»“æœ",
                "",
                f"- **å¹³å‡å‡†ç¡®ç‡**: {self.best_avg_accuracy:.2f}%",
                f"- **æœ€é«˜å‡†ç¡®ç‡**: {self.best_max_accuracy:.2f}%",
                f"- **ç›¸æ¯”åŸºçº¿æå‡**: {improvement:+.2f}%",
                "",
            ])
            
            # ä» best_meta.json åŠ è½½å„å±‚è¯¦ç»†ç»“æœ
            meta_path = os.path.join(self.best_output_dir, "best_meta.json")
            if os.path.exists(meta_path):
                try:
                    with open(meta_path, "r", encoding="utf-8") as f:
                        meta = json.load(f)
                    
                    layer_details = meta.get("layer_details", [])
                    if layer_details:
                        report_lines.extend([
                            "### å„å±‚è¯¦ç»†ç»“æœ",
                            "",
                            "| å±‚ | å‡†ç¡®ç‡ | æ­£ç¡®/æ€»æ•° | Gateå€¼ | ç›¸æ¯”åŸºçº¿ |",
                            "|-----|--------|-----------|--------|----------|",
                        ])
                        
                        for lr in sorted(layer_details, key=lambda x: x["accuracy"], reverse=True):
                            diff = lr["accuracy"] - self.search_results.baseline_accuracy
                            report_lines.append(
                                f"| L{lr['layer']} | {lr['accuracy']:.2f}% | "
                                f"{lr['correct']}/{lr['total']} | {lr['gate']:.4f} | {diff:+.2f}% |"
                            )
                except Exception:
                    pass
        elif self.search_results.best_experiment_idx >= 0:
            best_exp = self.search_results.experiments[self.search_results.best_experiment_idx]
            improvement = best_exp.avg_accuracy - self.search_results.baseline_accuracy
            
            report_lines.extend([
                "## 3. ğŸ† æœ€ä½³é…ç½®",
                "",
                "### æœ€ä½³å‚æ•°",
                "",
                "| å‚æ•° | å€¼ |",
                "|------|-----|",
            ])
            
            for param, value in best_exp.params.items():
                report_lines.append(f"| {param} | {value} |")
            
            report_lines.extend([
                "",
                "### æœ€ä½³ç»“æœ",
                "",
                f"- **å¹³å‡å‡†ç¡®ç‡**: {best_exp.avg_accuracy:.2f}%",
                f"- **æœ€é«˜å‡†ç¡®ç‡**: {best_exp.max_accuracy:.2f}% (Layer {best_exp.best_layer})",
                f"- **ç›¸æ¯”åŸºçº¿æå‡**: {improvement:+.2f}%",
                f"- **è®­ç»ƒè€—æ—¶**: {format_time(best_exp.total_time)}",
                "",
                "### å„å±‚è¯¦ç»†ç»“æœ",
                "",
                "| å±‚ | å‡†ç¡®ç‡ | æ­£ç¡®/æ€»æ•° | Gateå€¼ | ç›¸æ¯”åŸºçº¿ |",
                "|-----|--------|-----------|--------|----------|",
            ])
            
            for lr in sorted(best_exp.layer_results, key=lambda x: x.accuracy, reverse=True):
                if lr.error:
                    report_lines.append(f"| L{lr.layer} | ERROR | - | - | - |")
                else:
                    diff = lr.accuracy - self.search_results.baseline_accuracy
                    report_lines.append(
                        f"| L{lr.layer} | {lr.accuracy:.2f}% | "
                        f"{lr.correct}/{lr.total} | {lr.gate:.4f} | {diff:+.2f}% |"
                    )
        
        # æ‰€æœ‰å®éªŒç»“æœ
        report_lines.extend([
            "",
            "## 4. æ‰€æœ‰å®éªŒç»“æœ",
            "",
            "æŒ‰å¹³å‡å‡†ç¡®ç‡æ’åºï¼š",
            "",
            "| æ’å | kl_beta | kl_warmup | lr | å¹³å‡å‡†ç¡®ç‡ | æœ€ä½³å±‚ | æœ€é«˜å‡†ç¡®ç‡ | çŠ¶æ€ |",
            "|------|---------|-----------|-----|-----------|--------|-----------|------|",
        ])
        
        # æŒ‰å‡†ç¡®ç‡æ’åº
        sorted_experiments = sorted(
            enumerate(self.search_results.experiments),
            key=lambda x: x[1].avg_accuracy if x[1].status == "completed" else -1,
            reverse=True
        )
        
        for rank, (idx, exp) in enumerate(sorted_experiments, 1):
            if exp.status == "completed":
                is_best = " ğŸ†" if (self.best_params and exp.params == self.best_params) else ""
                report_lines.append(
                    f"| {rank} | {exp.params['kl_beta']} | "
                    f"{exp.params['kl_warmup_steps']} | "
                    f"{exp.params['abc_learning_rate']} | "
                    f"{exp.avg_accuracy:.2f}% | L{exp.best_layer} | "
                    f"{exp.max_accuracy:.2f}% | âœ“{is_best} |"
                )
            else:
                report_lines.append(
                    f"| {rank} | {exp.params['kl_beta']} | "
                    f"{exp.params['kl_warmup_steps']} | "
                    f"{exp.params['abc_learning_rate']} | "
                    f"- | - | - | âŒ {exp.error_message[:20] if exp.error_message else 'Failed'}... |"
                )
        
        # åˆ†æä¸å»ºè®®
        report_lines.extend([
            "",
            "## 5. åˆ†æä¸å»ºè®®",
            "",
        ])
        
        if self.search_results.completed_experiments > 0:
            completed_exps = [e for e in self.search_results.experiments 
                            if e.status == "completed"]
            
            # åˆ†æå„å‚æ•°çš„å½±å“
            param_analysis = {}
            for param in self.param_grid.keys():
                param_analysis[param] = {}
                for exp in completed_exps:
                    val = exp.params[param]
                    if val not in param_analysis[param]:
                        param_analysis[param][val] = []
                    param_analysis[param][val].append(exp.avg_accuracy)
            
            report_lines.append("### å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
            report_lines.append("")
            
            for param, val_accs in param_analysis.items():
                report_lines.append(f"#### {param}")
                report_lines.append("")
                report_lines.append("| å–å€¼ | å¹³å‡å‡†ç¡®ç‡ | æ ·æœ¬æ•° |")
                report_lines.append("|------|-----------|--------|")
                
                for val in sorted(val_accs.keys()):
                    accs = val_accs[val]
                    avg = sum(accs) / len(accs)
                    report_lines.append(f"| {val} | {avg:.2f}% | {len(accs)} |")
                
                report_lines.append("")
            
            # å»ºè®®
            report_lines.append("### å»ºè®®")
            report_lines.append("")
            
            if self.best_avg_accuracy > self.search_results.baseline_accuracy:
                report_lines.append(
                    f"1. **æ¨èä½¿ç”¨æœ€ä½³é…ç½®**: {format_params(self.best_params)}"
                )
                report_lines.append(
                    f"2. **æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°**: `{self.best_output_dir}`"
                )
                report_lines.append(
                    f"3. **é¢„æœŸæå‡**: ç›¸æ¯”åŸºçº¿æå‡ "
                    f"{self.best_avg_accuracy - self.search_results.baseline_accuracy:+.2f}%"
                )
            else:
                report_lines.append(
                    "âš ï¸ å½“å‰å‚æ•°é…ç½®æœªèƒ½è¶…è¶ŠåŸºçº¿ï¼Œå»ºè®®ï¼š\n"
                    "1. æ‰©å¤§å‚æ•°æœç´¢èŒƒå›´\n"
                    "2. å¢åŠ è®­ç»ƒ epoch\n"
                    "3. æ£€æŸ¥æ•°æ®è´¨é‡"
                )
        
        report_lines.extend([
            "",
            "---",
            "",
            f"æŠ¥å‘Šç”Ÿæˆäº: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        ])
        
        # å†™å…¥æŠ¥å‘Š
        with open(report_file, "w", encoding="utf-8") as f:
            f.write("\n".join(report_lines))
        
        self.logger.info("")
        self.logger.info("=" * 70)
        self.logger.info("æŠ¥å‘Šå·²ç”Ÿæˆ")
        self.logger.info("=" * 70)
        self.logger.info(f"JSON ç»“æœ: {json_file}")
        self.logger.info(f"ä¸­æ–‡æŠ¥å‘Š: {report_file}")
        if self.best_avg_accuracy > 0:
            self.logger.info(f"æœ€ä½³æ¨¡å‹: {self.best_output_dir}")
        
        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        if self.best_avg_accuracy > 0:
            print(f"ğŸ† æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {self.best_output_dir}")


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    best_dir = os.path.join(BEST_OUTPUT_BASE, f"{DATASET}_best")
    
    print("=" * 70)
    print("ABC Vector è¶…å‚æ•°è‡ªåŠ¨æœç´¢")
    print("=" * 70)
    print(f"æ¨¡å‹: {MODEL_PATH.split('/')[-1]}")
    print(f"æ•°æ®é›†: {DATASET}")
    print(f"è¾“å‡ºç›®å½•: {RESULTS_DIR}")
    print(f"æœ€ä½³æ¨¡å‹ç›®å½•: {best_dir}")
    print(f"å‚æ•°ç»„åˆæ•°: {len(list(product(*PARAM_GRID.values())))}")
    print("=" * 70)
    
    try:
        # åˆ›å»ºæœç´¢å™¨
        searcher = ABCHyperparameterSearch(
            model_path=MODEL_PATH,
            model_name=MODEL_NAME,
            dataset=DATASET,
            data_path=DATA_PATH,
            results_dir=RESULTS_DIR,
            param_grid=PARAM_GRID,
            fixed_params=FIXED_PARAMS,
            layers=LAYERS,
            best_output_base=BEST_OUTPUT_BASE,
        )
        
        # è¿è¡Œæœç´¢
        searcher.run_search()
        
        print("\nâœ… è¶…å‚æ•°æœç´¢å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æœç´¢")
        send_email(
            subject=f"âš ï¸ ä¸­æ–­: {DATASET} è¶…å‚æ•°æœç´¢",
            body="ç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­äº†è¶…å‚æ•°æœç´¢ã€‚\nä¸­é—´ç»“æœå·²ä¿å­˜ã€‚",
            is_error=True
        )
        sys.exit(1)
        
    except Exception as e:
        print(f"\n\nâŒ æœç´¢å¤±è´¥: {e}")
        traceback.print_exc()
        
        send_email(
            subject=f"âŒ å¤±è´¥: {DATASET} è¶…å‚æ•°æœç´¢",
            body=f"è¶…å‚æ•°æœç´¢å› é”™è¯¯ç»ˆæ­¢ã€‚\n\né”™è¯¯ä¿¡æ¯:\n{str(e)}\n\n"
                 f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}",
            is_error=True
        )
        sys.exit(1)


if __name__ == "__main__":
    main()